{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PPMI_SVD_Word_similarity_Analysis",
   "id": "fc97e6f55303d433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ###### Install necessary libraries\n",
    " ###### Ensure that you  have numpy and scipy installed for matrix operations and SVD\n",
    " ###### Numpy is a library for numerical operations, and SciPy provides scientific computing capabilities "
   ],
   "id": "61e1dee818ed742e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-22T13:46:49.936571Z",
     "start_time": "2024-05-22T13:46:49.614267Z"
    }
   },
   "source": "# python install numpy scipy",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ryanqchiqache/anaconda3/bin/python: can't open file '/Users/ryanqchiqache/PycharmProjects/Machine-Learning-Learning-Center/learningML/install': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import libraries\n",
    " This cell imports the required libraries for numerical computations and sparse matrix operations.\n",
    " - numpy: Provides support for large multi-dimensional arrays and matrices, along with a large collection of mathematical functions.\n",
    " - scipy.sparse: Contains functions for working with sparse matrices, which are efficient for storing large, mostly empty matrices.\n",
    " - scipy.sparse.linalg: Contains functions for performing linear algebra operations on sparse matrices."
   ],
   "id": "e6584269d282c099"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:34:11.193126Z",
     "start_time": "2024-05-22T14:34:11.189131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n"
   ],
   "id": "5df55a76e47b40b9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Corpus \n",
    "- This cell define a small sample corpus. In practice, you would use a larger, more diverse corpus."
   ],
   "id": "b0680bf6f3b497eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:36:33.205465Z",
     "start_time": "2024-05-22T14:36:33.201183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample Corpus \n",
    "corpus = [\"the quick brown fox jumps over the lazy dog\", \"never jump over the lazy dog quickly\", \"bright stars shine in the dark sky\",\n",
    "    \"the quick brown fox and the lazy dog are friends\",\"a fast and agile fox easily escape capture\",\"dogs are loyal and faithful animals\",\n",
    "    \"the brown dog sleeps soundly on the porch\", \"foxes are cunning and clever creatures\",\"jumping over obstacles is a fun game\",\n",
    "    \"the lazy dog never jumps over anything\",\"quick thinking and swift actions save the day\",\"a fox and a dog play together in the yard\",\n",
    "    \"in the quiet forest, foxes hunt at night\",\"the dog barks loudly at strangers\",\"an agile fox can leap over high fences\",\n",
    "    \"lazy days are perfect for relaxing in the sun\",\"dogs and foxes have different habits\",\"the quick fox outsmarts the slow dog\",\n",
    "    \"barking dogs seldom bite\",\"the brown fox jumps over the lazy dog again\",\"every dog has its day\",\"the sky is clear and full of bright stars\",\n",
    "    \"foxes hide in their dens during the day\",\"dogs love to chase after balls\",\"the clever fox finds a way to get food\",\n",
    "    \"the dog runs fast to catch the ball\",\"foxes and dogs sometimes share the same habitat\",\"a lazy dog and a quick fox make an odd pair\",\n",
    "    \"the agile fox swiftly moves through the forest\",\"dogs are man's best friend\",\"the sly fox sneaks past the guard dog\",\n",
    "    \"both foxes and dogs have sharp senses\",\"the brown dog lazily watches the quick fox\",\"jumping is an activity enjoyed by many animals\",\n",
    "    \"the sun sets behind the mountains\"\n",
    "]"
   ],
   "id": "74dbe138d783ba39",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preprocess the Corpus :\n",
    "- We use a context window to define the surrounding words for each target word.\n",
    "- Steps :\n",
    "- 1. Split each sentence into words( tokens )\n",
    "- 2. For each word, define a context window (words surrounding the target word)\n",
    "- 3. Count how often each word appears with each context word.\n",
    "- the `words` set will contain all unique words in the corpus.\n",
    "- the `contexts` dictionary will count how many times each context word appears\n",
    "- the `cooccurence_count` dictionary will count co-occurences of word-context pairs "
   ],
   "id": "85b23694802fcd55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d73b4231e46d2df5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:36:34.960488Z",
     "start_time": "2024-05-22T14:36:34.954083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = set()\n",
    "contexts = {}\n",
    "cooccurence_count = {}\n",
    "\n",
    "for sentence in corpus : \n",
    "    tokens = sentence.split()\n",
    "    for i, word in enumerate(tokens):\n",
    "        words.add(word)\n",
    "        context = tokens[max(0, i-2):i] + tokens[i + 1:i + 3]\n",
    "        for context_word in context:\n",
    "            if (word, context_word) not in cooccurence_count:\n",
    "                cooccurence_count[word, context_word] = 0\n",
    "            cooccurence_count[word, context_word] += 1\n",
    "            if context_word not in contexts:\n",
    "                contexts[context_word] = 0\n",
    "            contexts[context_word] += 1\n",
    "            \n",
    "words = list(words)\n",
    "word_index = {word : i for i , word in enumerate(words)}"
   ],
   "id": "a26db345b38d8326",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the PPMI Matrix :\n",
    "\n",
    "- PPMI stands for Positive Pointwise Mutual Information. It measures the association strength between words and their context \n",
    "- Steps : \n",
    "1. Initialaze a square Matrix with dimensions equal the number of unique words\n",
    "2. Calculate the probability of each word and context word\n",
    "3. Compute the PPMI value for each word-context pair\n",
    "4. Fill the matrix with this PPMI \n",
    "- the PPMI value is calculated as : \n",
    "- PPMI (w, c) = max (log((P(w,c) / P(c) * P(w) * |D|, 0)\n",
    "- Where :\n",
    "- P(w,c) :  is the joint Probability of word w and context c.\n",
    "- P(c) :  is the Probability of word w.\n",
    "- P(w) : is the Probability of context word c.\n",
    "- |D| : is the total number of word-context pairs in the corpus. "
   ],
   "id": "82497b6bd4558a47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:36:36.129904Z",
     "start_time": "2024-05-22T14:36:36.106810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create the PPMI matrix\n",
    "word_context_matrix = np.zeros((len(words), len(words)))\n",
    "\n",
    "for (word, context_word), count in cooccurence_count.items():\n",
    "    word_prob = sum(cooccurence_count[(word, c)] for c in words)\n",
    "    context_prob = contexts[context_word]\n",
    "    joint_prob = count\n",
    "    ppmi = max(np.log((joint_prob / (word_prob * context_prob))) * len(corpus), 0)\n",
    "    word_context_matrix[word_index[word], word_index[context_word]] = ppmi\n",
    "\n"
   ],
   "id": "431bd038f7adcd0d",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('an', 'share')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m word_context_matrix \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(words), \u001B[38;5;28mlen\u001B[39m(words)))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (word, context_word), count \u001B[38;5;129;01min\u001B[39;00m cooccurence_count\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 5\u001B[0m     word_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcooccurence_count\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mwords\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     context_prob \u001B[38;5;241m=\u001B[39m contexts[context_word]\n\u001B[1;32m      7\u001B[0m     joint_prob \u001B[38;5;241m=\u001B[39m count\n",
      "Cell \u001B[0;32mIn[36], line 5\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      2\u001B[0m word_context_matrix \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;28mlen\u001B[39m(words), \u001B[38;5;28mlen\u001B[39m(words)))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (word, context_word), count \u001B[38;5;129;01min\u001B[39;00m cooccurence_count\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m----> 5\u001B[0m     word_prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(\u001B[43mcooccurence_count\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m words)\n\u001B[1;32m      6\u001B[0m     context_prob \u001B[38;5;241m=\u001B[39m contexts[context_word]\n\u001B[1;32m      7\u001B[0m     joint_prob \u001B[38;5;241m=\u001B[39m count\n",
      "\u001B[0;31mKeyError\u001B[0m: ('an', 'share')"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Apply the SVD :\n",
    "- this cell applies the SVD to the PPMI matrix to reduce its dimensionality\n",
    "- `SVD` stand for Singular Value Decomposition. It decomposes the matrix into thre matrices (U, Sigma, VT), Which helps in reducing noise and extracting meaninful patterns\n",
    "- SVD is performed as follows :\n",
    "- PPMI = U * Sigma * VT\n",
    "- WHERE :\n",
    "- `U` contains the left singular vectors.\n",
    "- `Sigma` contains the singular values (diagonal matrix)\n",
    "- `VT` contains the right singular vector ( transpose of V\n",
    "\n",
    "- the `k` parameter specifies the number of singular values and vectors to compute, effectively reducing the matris to `k` dimensions "
   ],
   "id": "f3daca115a61a8b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:31:31.067296Z",
     "start_time": "2024-05-22T14:31:31.050614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply SVD\n",
    "U, Sigma, VT = svds(coo_matrix(word_context_matrix), k=50)"
   ],
   "id": "612f04a959188be4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Get the Reduced Word Vectors\n",
    "- This cell multiplies the matrices obtained from SVD to get the reduced word vectors.\n",
    "- These vectors capture the semantic relationships between words.\n",
    " \n",
    "- By multiplying U and Sigma, we obtain the reduced dimensionality word vectors.\n",
    "- These vectors can be used to measure similarity between words and to find similar words."
   ],
   "id": "943d6249f773376"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:31:32.487319Z",
     "start_time": "2024-05-22T14:31:32.483663Z"
    }
   },
   "cell_type": "code",
   "source": "word_vetors = np.dot(U, np.diag(Sigma))",
   "id": "2b74dee8dc50267c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Function to Find Similar Words\n",
    "- This cell defines a function to find the most similar words to a given word based on cosine similarity.\n",
    "- Steps:\n",
    "1. Retrieve the vector for the target word.\n",
    "2. Compute the cosine similarity between the target word vector and all other word vectors.\n",
    "3. Sort the words by similarity score in descending order.\n",
    "4. Return the top N most similar words. \n",
    "- `Cosine similarity` is calculated as:\n",
    "-  similarity(A, B) = (A . B) / (||A|| * ||B||)\n",
    "- Where:\n",
    "- A . B is the dot product of vectors A and B.\n",
    " - ||A|| and ||B|| are the magnitudes (norms) of vectors A and B."
   ],
   "id": "496c89d42604365"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:31:33.918881Z",
     "start_time": "2024-05-22T14:31:33.914513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exampple : fine similar words \n",
    "def find_similar(word, top_n=5 ):\n",
    "    if word not in word_index : \n",
    "        return []\n",
    "    word_vec = word_vetors[word_index[word]]\n",
    "    similarities = np.dot(word_vetors ,word_vec)\n",
    "    sorted_indices = np.argsort(-similarities)\n",
    "    similar_words= [(words[i], similarities[i]) for i in sorted_indices[:top_n]]\n",
    "    return similar_words"
   ],
   "id": "7af65b8bdd5fbe0b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find similar words to \"quick\"",
   "id": "29a2036ebbd24414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:32:05.331915Z",
     "start_time": "2024-05-22T14:32:05.328147Z"
    }
   },
   "cell_type": "code",
   "source": "print(find_similar(\"fox\"))",
   "id": "9a3fc40463c53e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('share', 0.0), ('sun', 0.0), ('the', 0.0), ('can', 0.0), ('brown', 0.0)]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "149984923a248467"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
