{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PPMI_SVD_Word_similarity_Analysis",
   "id": "fc97e6f55303d433"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " ###### Install necessary libraries\n",
    " ###### Ensure that you  have numpy and scipy installed for matrix operations and SVD\n",
    " ###### Numpy is a library for numerical operations, and SciPy provides scientific computing capabilities "
   ],
   "id": "61e1dee818ed742e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T11:05:24.976822Z",
     "start_time": "2024-05-23T11:05:24.973315Z"
    }
   },
   "source": "# python install numpy scipy",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Import libraries\n",
    " This cell imports the required libraries for numerical computations and sparse matrix operations.\n",
    " - numpy: Provides support for large multi-dimensional arrays and matrices, along with a large collection of mathematical functions.\n",
    " - scipy.sparse: Contains functions for working with sparse matrices, which are efficient for storing large, mostly empty matrices.\n",
    " - scipy.sparse.linalg: Contains functions for performing linear algebra operations on sparse matrices."
   ],
   "id": "e6584269d282c099"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:09.029620Z",
     "start_time": "2024-07-11T16:58:09.026424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "\n"
   ],
   "id": "5df55a76e47b40b9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Corpus \n",
    "- This cell define a small sample corpus. In practice, you would use a larger, more diverse corpus."
   ],
   "id": "b0680bf6f3b497eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:10.361771Z",
     "start_time": "2024-07-11T16:58:10.358906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample Corpus \n",
    "corpus = [\"the quick brown fox jumps over the lazy dog\", \"never jump over the lazy dog quickly\", \"bright stars shine in the dark sky\",\n",
    "    \"the quick brown fox and the lazy dog are friends\", \"the quick brown fox jumps over the lazy dog quickly\"\n",
    "]\n"
   ],
   "id": "74dbe138d783ba39",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Preprocess the Corpus :\n",
    "- We use a context window to define the surrounding words for each target word.\n",
    "- Steps :\n",
    "- 1. Split each sentence into words( tokens )\n",
    "- 2. For each word, define a context window (words surrounding the target word)\n",
    "- 3. Count how often each word appears with each context word.\n",
    "- the `words` set will contain all unique words in the corpus.\n",
    "- the `contexts` dictionary will count how many times each context word appears\n",
    "- the `cooccurence_count` dictionary will count co-occurences of word-context pairs "
   ],
   "id": "85b23694802fcd55"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d73b4231e46d2df5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:11.794602Z",
     "start_time": "2024-07-11T16:58:11.789718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "words = set()\n",
    "contexts = {}\n",
    "cooccurence_count = {}\n",
    "\n",
    "for sentence in corpus : \n",
    "    tokens = sentence.split()\n",
    "    for i, word in enumerate(tokens):\n",
    "        words.add(word)\n",
    "        context = tokens[max(0, i-2):i] + tokens[i + 1:i + 3]\n",
    "        for context_word in context:\n",
    "            if (word, context_word) not in cooccurence_count:\n",
    "                cooccurence_count[word, context_word] = 0\n",
    "            cooccurence_count[word, context_word] += 1\n",
    "            if context_word not in contexts:\n",
    "                contexts[context_word] = 0\n",
    "            contexts[context_word] += 1\n",
    "            \n",
    "words = list(words)\n",
    "word_index = {word : i for i , word in enumerate(words)}"
   ],
   "id": "a26db345b38d8326",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Create the PPMI Matrix :\n",
    "\n",
    "- PPMI stands for Positive Pointwise Mutual Information. It measures the association strength between words and their context \n",
    "- Steps : \n",
    "1. Initialaze a square Matrix with dimensions equal the number of unique words\n",
    "2. Calculate the probability of each word and context word\n",
    "3. Compute the PPMI value for each word-context pair\n",
    "4. Fill the matrix with this PPMI \n",
    "- the PPMI value is calculated as : \n",
    "- PPMI (w, c) = max (log((P(w,c) / P(c) * P(w) * |D|, 0)\n",
    "- Where :\n",
    "- P(w,c) :  is the joint Probability of word w and context c.\n",
    "- P(c) :  is the Probability of word w.\n",
    "- P(w) : is the Probability of context word c.\n",
    "- |D| : is the total number of word-context pairs in the corpus. "
   ],
   "id": "82497b6bd4558a47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:13.412850Z",
     "start_time": "2024-07-11T16:58:13.383449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create the PPMI matrix\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "word_context_matrix = np.zeros((len(words), len(words)))\n",
    "\n",
    "for (word, context_word), count in cooccurence_count.items():\n",
    "    word_prob = sum(cooccurence_count.get((word, c), 0)for c in words)\n",
    "    context_prob = contexts.get(context_word, 0)\n",
    "    if context_prob == 0:\n",
    "        continue\n",
    "    joint_prob = count\n",
    "    ppmi = max(np.log((joint_prob / (word_prob * context_prob))) * len(corpus), 0)\n",
    "    word_context_matrix[word_index[word], word_index[context_word]] = ppmi\n",
    "\n",
    "\n",
    "ppmi_df = pd.DataFrame(word_context_matrix, index=words, columns=words) \n",
    "plt.figure(figsize = (10,10))\n",
    "sns.heatmap(ppmi_df, annot=True,fmt=\".2f\" , cmap=\"YlGn\", cbar=True)\n",
    "plt.title(\"PPMI Word Similarity Analysis\") \n",
    "plt.show()\n",
    "\n"
   ],
   "id": "431bd038f7adcd0d",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m\n\u001B[1;32m     13\u001B[0m     word_context_matrix[word_index[word], word_index[context_word]] \u001B[38;5;241m=\u001B[39m ppmi\n\u001B[1;32m     16\u001B[0m ppmi_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(word_context_matrix, index\u001B[38;5;241m=\u001B[39mwords, columns\u001B[38;5;241m=\u001B[39mwords) \n\u001B[0;32m---> 17\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfigsize\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m sns\u001B[38;5;241m.\u001B[39mheatmap(ppmi_df, annot\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,fmt\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;124m\"\u001B[39m , cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYlGn\u001B[39m\u001B[38;5;124m\"\u001B[39m, cbar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     19\u001B[0m plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPPMI Word Similarity Analysis\u001B[39m\u001B[38;5;124m\"\u001B[39m) \n",
      "\u001B[0;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Apply the SVD :\n",
    "- this cell applies the SVD to the PPMI matrix to reduce its dimensionality\n",
    "- `SVD` stand for Singular Value Decomposition. It decomposes the matrix into thre matrices (U, Sigma, VT), Which helps in reducing noise and extracting meaninful patterns\n",
    "- SVD is performed as follows :\n",
    "- PPMI = U * Sigma * VT\n",
    "- WHERE :\n",
    "- `U` contains the left singular vectors.\n",
    "- `Sigma` contains the singular values (diagonal matrix)\n",
    "- `VT` contains the right singular vector ( transpose of V\n",
    "\n",
    "- the `k` parameter specifies the number of singular values and vectors to compute, effectively reducing the matris to `k` dimensions "
   ],
   "id": "f3daca115a61a8b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:26.535415Z",
     "start_time": "2024-07-11T16:58:26.528453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply SVD\n",
    "U, Sigma, VT = svds(coo_matrix(word_context_matrix), k=10)"
   ],
   "id": "612f04a959188be4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Get the Reduced Word Vectors\n",
    "- This cell multiplies the matrices obtained from SVD to get the reduced word vectors.\n",
    "- These vectors capture the semantic relationships between words.\n",
    " \n",
    "- By multiplying U and Sigma, we obtain the reduced dimensionality word vectors.\n",
    "- These vectors can be used to measure similarity between words and to find similar words."
   ],
   "id": "943d6249f773376"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:27.909367Z",
     "start_time": "2024-07-11T16:58:27.906449Z"
    }
   },
   "cell_type": "code",
   "source": "word_vetors = np.dot(U, np.diag(Sigma))",
   "id": "2b74dee8dc50267c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Function to Find Similar Words\n",
    "- This cell defines a function to find the most similar words to a given word based on cosine similarity.\n",
    "- Steps:\n",
    "1. Retrieve the vector for the target word.\n",
    "2. Compute the cosine similarity between the target word vector and all other word vectors.\n",
    "3. Sort the words by similarity score in descending order.\n",
    "4. Return the top N most similar words. \n",
    "- `Cosine similarity` is calculated as:\n",
    "-  similarity(A, B) = (A . B) / (||A|| * ||B||)\n",
    "- Where:\n",
    "- A . B is the dot product of vectors A and B.\n",
    " - ||A|| and ||B|| are the magnitudes (norms) of vectors A and B."
   ],
   "id": "496c89d42604365"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:30.153598Z",
     "start_time": "2024-07-11T16:58:30.150013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exampple : fine similar words \n",
    "def find_similar(word, top_n=10 ):\n",
    "    if word not in word_index : \n",
    "        return []\n",
    "    word_vec = word_vetors[word_index[word]]\n",
    "    similarities = np.dot(word_vetors ,word_vec)\n",
    "    sorted_indices = np.argsort(-similarities)\n",
    "    similar_words= [(words[i], similarities[i]) for i in sorted_indices[:top_n]]\n",
    "    return similar_words"
   ],
   "id": "7af65b8bdd5fbe0b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Find similar words to \"quick\"",
   "id": "29a2036ebbd24414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:58:32.439535Z",
     "start_time": "2024-07-11T16:58:32.436265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(find_similar(\"fox\"))\n",
    "\n"
   ],
   "id": "9a3fc40463c53e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('never', 0.0), ('shine', 0.0), ('and', 0.0), ('dog', 0.0), ('in', 0.0), ('quickly', 0.0), ('over', 0.0), ('the', 0.0), ('lazy', 0.0), ('jumps', 0.0)]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d9d871fa29382725"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
