project:
  name: "computerVisionBach-segmentation"
  dataset: "flair"     # one of: ["flair", "dlr"]
  description: "Default config for segmentation training"
  version: 1.0

model:
  name: "unet_resnet101"             # e.g., "unet_resnet101", "DeepLabV3+", "SegFormer", "Mask2Former", "UPerNet", "FPN", "UnetPP", "UNet"
  num_classes: 13
  ignore_class_index: 255
  patch_size: 512
  overlap: 0.5
  patchify_enabled: true
  smp:
    encoder_name: "resnet34"
    encoder_weights: "imagenet"
    in_channels: 3
    encoder_output_stride: 16

  hf:
    checkpoint:
      segformer:   "nvidia/segformer-b2-finetuned-ade-512-512"
      mask2former: "facebook/mask2former-swin-small-ade-semantic"
      upernet:     "openmmlab/upernet-swin-small"
    processor:
      reduce_labels: false
      do_rescale: false

training:
  batch_size: 14
  num_epochs: 80
  learning_rate: 0.001
  random_seed: 42
  patience: 30               # early stopping on mIoU
  num_reconstructions: 4
  scheduler:
    type: "ReduceLROnPlateau"
    mode: "max"
    patience: 5
    factor: 0.5
    verbose: true
  optimizer:
    type: "Adam"
    weight_decay: 0.0

data:
  # DLR Dataset
  dlr:
    root_dir: "/home/ryqc/data/Machine-Deep-Learning-Center/computerVisionBach/DLR_dataset"
    rare_class_ids: []

  # FLAIR Dataset
  flair:
    base_dir: "/home/ryqc/data/flair_dataset"
    train_csv: "/home/ryqc/data/flair_dataset/cleaned-train01.csv"
    val_csv:   "/home/ryqc/data/flair_dataset/cleaned-test01.csv"
    test_csv:  "/home/ryqc/data/flair_dataset/cleaned-test01.csv"
    used_labels: [1, 2, 3, 6, 7, 8, 10, 11, 13, 18]
    rare_class_ids: [1, 3, 5, 7, 11, 12]

pretrained_processors:
  segformer: "nvidia/segformer-b2-finetuned-ade-512-512"
  mask2former: "facebook/mask2former-swin-small-ade-semantic"
  reduce_labels: false
  do_rescale: false

augmentation:
  horizontal_flip: true
  vertical_flip: false
  random_crop: false

paths:
  # All artifacts in one tidy tree; change these once, everything follows.
  artifacts_root: "/home/ryqc/experiments/segmentation"   # master root for all outputs below

  # TensorBoard logs
  tensorboard:
    dir: "${paths.artifacts_root}/runs"                    # base runs dir
    experiment_prefix: "${project.dataset}_experiment_${model.name}"   # final folder can append timestamp in code
    add_timestamp: true                                    # your script can append datetime if true

  # Checkpoints
  checkpoints:
    dir: "${paths.artifacts_root}/checkpoints"
    # Filename pattern tokens you can format in code:
    # {model}, {dataset}, {epoch}, {miou}, {timestamp}
    filename_pattern: "{model}_{dataset}_{timestamp}.pth"
    save_best_only: true                                   # save the best (by mIoU)
    metric: "mIoU_macro"                                   # which val metric defines "best"

  # Visualizations / samples
  visualizations:
    dir: "${paths.artifacts_root}/viz"

  # Logs (text)
  logs:
    dir: "${paths.artifacts_root}/logs"

misc:
  print_encoder_names: true
